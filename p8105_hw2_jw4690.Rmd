---
title: "p8105_hw2_jw4690"
author: "Jingxi Wang"
date: "2024-09-26"
output: github_document
---

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

```{r}
NYCSubway_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4,
         route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

The dataset details NYC subway entrances and exits, including the line, station name, station latitude, station longitude, routes, entrance type, entry, vending, and ADA. Cleaning steps included clean names, selecting needed variables, and converting entry from "YES"/"NO" to TRUE/FALSE. The cleaned dataset has `r nrow(NYCSubway_df)` of rows and  `r ncol(NYCSubway_df)` columns. The data is tidy, with each row representing a unique entrance/exit and each column a distinct variable.

```{r}
distinct_stations = NYCSubway_df |>
  distinct(line, station_name)
```

There are `r nrow(distinct_stations)` distinct stations.

```{r}
ADA_compliant = NYCSubway_df |>
  filter(ada == "TRUE") |>
  distinct(line, station_name)
```

There are `r nrow(ADA_compliant)` stations are ADA compliant.

```{r}
without_vending = NYCSubway_df |>
  filter(vending == "NO")
```

The proportion of station entrances / exits without vending allow entrance is `r mean(as.numeric(pull(without_vending, var = entry, name = NULL)))`.

```{r}
NYCSubway_df = NYCSubway_df |>
  mutate(across(route1:route11, as.character))

routes = NYCSubway_df |>
  pivot_longer(cols = route1:route11,
               names_to = "route_number",
               values_to = "route_name") |>
  filter(!is.na(route_name))
```

```{r}
A_train = routes |>
  filter(route_name == "A") |>
  distinct(line, station_name)
```

`r nrow(A_train)` distinct stations serve the A train.

```{r}
A_train_ADA = routes |>
  filter(route_name == "A", ada == "TRUE") |>
  distinct(line, station_name)
```

Of the stations that serve the A train, `r nrow(A_train_ADA)` are ADA compliant.

## Problem 2

```{r}
TrashWheel_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 1) |>
  janitor::clean_names() |>
  select_if(~ !all(is.na(.))) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)))
```

```{r}
Professor_Trash_Wheel = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 2) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))

Professor_Trash_Wheel <- Professor_Trash_Wheel %>% filter(row_number() <= n()-1)
```


```{r}
Gwynnda_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 4) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))
```

```{r}
TrashWheel_df = TrashWheel_df |>
  mutate(source = "MrTrash_Wheel", .before = dumpster)

Professor_Trash_Wheel = Professor_Trash_Wheel |>
  mutate(source = "Professor_Trash_Wheel", .before = dumpster)

Gwynnda_df = Gwynnda_df |>
  mutate(source = "Gwynnda", .before = dumpster)
```

```{r}
Professor_Trash_Wheel = Professor_Trash_Wheel |>
  mutate(sports_balls = NA)

Gwynnda_df = Gwynnda_df |>
  mutate(glass_bottles = NA, sports_balls = NA)

combined_df = rbind(TrashWheel_df, Professor_Trash_Wheel, Gwynnda_df)
```

The combined dataset from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel contains `r nrow(combined_df)` observations. Key variables include source, dumpster, month, year, date, weight in tons, volume in cubic yards, plastic bottles, polystyrene, cigarette butts, glass bottles, plastic bags, wrappers, sports balls, homes powered. The total weight of trash collected by Professor Trash Wheel is `r sum(Professor_Trash_Wheel$weight_tons)`. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r sum((Gwynnda_df %>% filter(month == "June" & year == 2022))$cigarette_butts)`. 

## Problem 3

```{r}
bakers_df = read_csv("./data/gbb_datasets/gbb_datasets/bakers.csv") |>
  janitor::clean_names()

bakes_df = read_csv("./data/gbb_datasets/gbb_datasets/bakes.csv") |>
  janitor::clean_names()

results_df = read_csv("./data/gbb_datasets/gbb_datasets/results.csv", skip = 2) |>
  janitor::clean_names()
```

```{r}
colnames(bakers_df)[colnames(bakers_df) == 'baker_name'] <- 'baker'
bakers_df$baker = sapply(strsplit(bakers_df$baker, " "), `[`, 1)
```

```{r}
combined_bake = merge(bakers_df, bakes_df, all = TRUE)
combined_bake = merge(combined_bake, results_df, all = TRUE)

combined_bake = combined_bake |>
  filter(!is.na(result))
```

```{r}
write.csv(combined_bake, "./data/gbb_datasets/gbb_datasets/combined_bake.csv", row.names = FALSE)
```

For the data cleaning process, I began by inspecting and cleaning each dataset individually. And I find out the inconsistency in baker names across the datasets. The bakers.csv file listed the full names of bakers, while the other datasets only used first names. This discrepancy prevented the datasets from merging correctly. To address this, I extracted the first names from bakers.csv to align with the format in the other datasets, allowing for a successful merge. After merging the datasets, I noticed that the results column contained numerous missing values. And I decided to remove these rows with missing data in the results section. This step ensured that our final dataset only included relevant and complete information about the bakers' competition results.

The final dataset describe the bakers' demographic information, their performance in signature and showstopper challenges, and their competition outcomes. It now has no missing values in the result-related columns, making it suitable for further analysis of bakersâ€™ performances throughout the competition. 

```{r}
star_baker_winner = combined_bake |>
  filter(series >= 5 & series <= 10 & result %in% c("STAR BAKER", "WINNER"))

star_baker_table = star_baker_winner |>
  select(series, baker, episode, result) |>
  arrange(series, baker, episode)

print(star_baker_table)
```

Based on the table,  if a baker winning multiple Star Baker titles across episodes, they tend to become strong contenders for the final win. For instance, in several seasons, contestants who won multiple Star Baker awards went on to win the competition. This pattern suggests some predictability.

However, there are seasons where contestants who performed moderately throughout the competition managed to outperform others in the final episode, leading to surprise winners. In a few cases, Star Bakers from earlier episodes were eliminated in later rounds, adding unpredictability to the show's outcomes.

```{r}
viewer_df = read_csv("./data/gbb_datasets/gbb_datasets/viewers.csv") |>
  janitor::clean_names()

head(viewer_df, 10)
```

```{r}
avg_view_1 = mean(viewer_df$series_1, na.rm = TRUE)

avg_view_5 = mean(viewer_df$series_5, na.rm = TRUE)
```

the average viewership in Season 1 is `r avg_view_1` , and `r avg_view_5` in Season 5.