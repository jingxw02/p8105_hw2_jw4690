p8105_hw2_jw4690
================
Jingxi Wang
2024-09-26

## Problem 1

``` r
NYCSubway_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") |>
  janitor::clean_names() |>
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4,
         route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) |>
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The dataset details NYC subway entrances and exits, including the line,
station name, station latitude, station longitude, routes, entrance
type, entry, vending, and ADA. Cleaning steps included clean names,
selecting needed variables, and converting entry from “YES”/“NO” to
TRUE/FALSE. The cleaned dataset has 1868 of rows and 19 columns. The
data is tidy, with each row representing a unique entrance/exit and each
column a distinct variable.

``` r
distinct_stations = NYCSubway_df |>
  distinct(line, station_name)
```

There are 465 distinct stations.

``` r
ADA_compliant = NYCSubway_df |>
  filter(ada == "TRUE") |>
  distinct(line, station_name)
```

There are 84 stations are ADA compliant.

``` r
without_vending = NYCSubway_df |>
  filter(vending == "NO")
```

The proportion of station entrances / exits without vending allow
entrance is 0.3770492.

``` r
NYCSubway_df = NYCSubway_df |>
  mutate(across(route1:route11, as.character))

routes = NYCSubway_df |>
  pivot_longer(cols = route1:route11,
               names_to = "route_number",
               values_to = "route_name") |>
  filter(!is.na(route_name))
```

``` r
A_train = routes |>
  filter(route_name == "A") |>
  distinct(line, station_name)
```

60 distinct stations serve the A train.

``` r
A_train_ADA = routes |>
  filter(route_name == "A", ada == "TRUE") |>
  distinct(line, station_name)
```

Of the stations that serve the A train, 17 are ADA compliant.

## Problem 2

``` r
TrashWheel_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 1) |>
  janitor::clean_names() |>
  select_if(~ !all(is.na(.))) |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
Professor_Trash_Wheel = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 2) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))

Professor_Trash_Wheel <- Professor_Trash_Wheel %>% filter(row_number() <= n()-1)
```

``` r
Gwynnda_df = 
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", sheet = 4) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster))
```

``` r
TrashWheel_df = TrashWheel_df |>
  mutate(source = "MrTrash_Wheel", .before = dumpster)

Professor_Trash_Wheel = Professor_Trash_Wheel |>
  mutate(source = "Professor_Trash_Wheel", .before = dumpster)

Gwynnda_df = Gwynnda_df |>
  mutate(source = "Gwynnda", .before = dumpster)
```

``` r
Professor_Trash_Wheel = Professor_Trash_Wheel |>
  mutate(sports_balls = NA)

Gwynnda_df = Gwynnda_df |>
  mutate(glass_bottles = NA, sports_balls = NA)

combined_df = rbind(TrashWheel_df, Professor_Trash_Wheel, Gwynnda_df)
```

The combined dataset from Mr. Trash Wheel, Professor Trash Wheel, and
Gwynnda Trash Wheel contains 1032 observations. Key variables include
source, dumpster, month, year, date, weight in tons, volume in cubic
yards, plastic bottles, polystyrene, cigarette butts, glass bottles,
plastic bags, wrappers, sports balls, homes powered. The total weight of
trash collected by Professor Trash Wheel is 246.74. The total number of
cigarette butts collected by Gwynnda in June of 2022 is 1.812^{4}.

## Problem 3

``` r
bakers_df = read_csv("./data/gbb_datasets/gbb_datasets/bakers.csv") |>
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df = read_csv("./data/gbb_datasets/gbb_datasets/bakes.csv") |>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df = read_csv("./data/gbb_datasets/gbb_datasets/results.csv", skip = 2) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
colnames(bakers_df)[colnames(bakers_df) == 'baker_name'] <- 'baker'
bakers_df$baker = sapply(strsplit(bakers_df$baker, " "), `[`, 1)
```

``` r
combined_bake = merge(bakers_df, bakes_df, all = TRUE)
combined_bake = merge(combined_bake, results_df, all = TRUE)

combined_bake = combined_bake |>
  filter(!is.na(result))
```

``` r
write.csv(combined_bake, "./data/gbb_datasets/gbb_datasets/combined_bake.csv", row.names = FALSE)
```

For the data cleaning process, I began by inspecting and cleaning each
dataset individually. And I find out the inconsistency in baker names
across the datasets. The bakers.csv file listed the full names of
bakers, while the other datasets only used first names. This discrepancy
prevented the datasets from merging correctly. To address this, I
extracted the first names from bakers.csv to align with the format in
the other datasets, allowing for a successful merge. After merging the
datasets, I noticed that the results column contained numerous missing
values. And I decided to remove these rows with missing data in the
results section. This step ensured that our final dataset only included
relevant and complete information about the bakers’ competition results.

The final dataset describe the bakers’ demographic information, their
performance in signature and showstopper challenges, and their
competition outcomes. It now has no missing values in the result-related
columns, making it suitable for further analysis of bakers’ performances
throughout the competition.
